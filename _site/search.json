[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PRC Data Challenge",
    "section": "",
    "text": "The Performance Review Commission (PRC) Data Challenge aims at engaging with data scientists, even without Aviation background, to create teams and compete to build an open Machine Learning (ML) model able to accurately infer the Actual TakeOff Weight (ATOW) of a flown flight."
  },
  {
    "objectID": "index.html#the-why-of-why",
    "href": "index.html#the-why-of-why",
    "title": "PRC Data Challenge",
    "section": "The why of Why",
    "text": "The why of Why\nWe got many questions about this challenge. We grouped and answered them as follows:\n\nWhy is the challenge focusing on ATOW?\nATOW is an important input for models estimating fuel burnt and derived gaseous emissions.\nThe current lack of openly available ATOW is typically compensated by assuming it to be equal to a certain percentage of the Maximum TakeOff Weight (MTOW) for the relevant aircraft model.\nWith this challenge we aim at making available a better way to estimate ATOW, i.e. an Estimated TakeOff Weight (ETOW).\nWhy an Open model?\nThe PRC (and many other Organizations, industrial actors and academia by the way) is interested in studies assessing the impact of Aviation to Climate Change. To this extent the availability of an open model allows for reproducibility, transparency of the results presented and in the end to trust in the performed analyses.\nWhy via a Data Challenge?\nThe PRC thinks that there is a great pool of Data Scientists that could help to define the open model of the Challenge, but above that, it is the importance to have a white box approach to the way the model is being built that drove the decision to setup a Data Challenge.\nThis transparency is a way to build trust, reproducibility and eventually evolve a collaboration to improve the understanding of (and reducing) the impact of Aviation to the environment."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This website describes the PRC Data Challenge.\nThe Performance Review Commission (PRC) was established in 1998 by EUROCONTROL’s Permanent Commission.\nIt provides objective information and independent advice to EUROCONTROL’s governing bodies on European air traffic management (ATM) performance.\nYou can find further details in the AIU Portal PRC page"
  },
  {
    "objectID": "index.html#the-data",
    "href": "index.html#the-data",
    "title": "PRC Data Challenge",
    "section": "The Data",
    "text": "The Data\nSee the Data page for more details."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "The participating teams will have access to two S3 buckets as follows:\nThe competition-data bucket contains the data for modeling while submissions holds the teams’ submission for ranking."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "PRC Data Challenge",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nfrom Google’s Analysis-Ready, Cloud Optimized (ARCO) ERA5:\nERA5 is the fifth generation of the European Centre for Medium-Range Weather Forecasts (ECMWF) Atmospheric Reanalysis, providing hourly estimates of a large number of atmospheric, land, and oceanic climate variables.\nThe Google Cloud Public Dataset Program hosts ERA5 data that spans from 1940 to recent days, covering the Earth on a 30 km grid and resolves the atmosphere using 137 levels from the surface up to a height of 80 km.↩︎"
  },
  {
    "objectID": "data.html#data-for-modeling",
    "href": "data.html#data-for-modeling",
    "title": "Data",
    "section": "Data for modeling",
    "text": "Data for modeling\nWe propose two data sets:\n\na flight list of (a subset of) flights (partially) flown in Europe in 2022\nthe relevant trajectories for the above flights as recorded/processed by OpenSky Network (OSN)\n\nThe data sets for the challenge are organized as follows:\ncompetition-data/\n├── challenge_set.csv\n├── submission_set.csv\n├── 2022-01-01.parquet\n├── 2022-01-02.parquet\n└── ...\nsubmissions/\n├── baba_submission_1720622222.csv.gz\n├── cucu_submission_1720690111.csv.gz\n└── ...\nEach daily trajectory parquet file contains (Automatic Dependent Surveillance–Broadcast (ADS-B) based) flown trajectories augmented with meteo information1.\nThe S3 bucket competition-data contains\n\nthe flight list, challenge_set.csv\nthe daily trajectories, 2022-01-02.parquet …\nthe submission template, submission_set.csv\n\n\nFlight List\nThe flight list provides details such as (column names in parenthesis, [units] in italic in square brackets when appropriate):\n\nflight identification: unique ID (flight_id), (obfuscated) callsign (callsign)\norigin/destination: Aerodrome of DEParture (ADEP) (adep [ICAO code]), Aerodrome of DEStination (ADES) (ades [ICAO code]) and ancillary info, i.e. airport name (name_adep, name_ades) and country code (country_code_adep, country_code_ades [ISO2C])\ntiming: date of flight (date [ISO 8601 UTC date]), Actual Off-Block Time (AOBT) (actual_offblock_time [ISO 8601 UTC date and time]), ARriVal Time (ARVT) (arrival_time [ISO 8601 UTC date and time); AOBT and ARVT from Network Manager (NM)\naircraft: aircraft type code (aircraft_type [ICAO aircraft type]), Wake Turbulence Category (WTC) (wtc)\nairline: (obfuscated) Aircraft Operator (AO) code (airline),\noperational values: flight duration (flight_duration [min]) , taxi-out time (taxiout_time [min]), route length (flown_distance [nmi]) , (estimated) TakeOff Weight (TOW) (tow [kg])\n\nFurther info material:\n\nAirport codes, and more: OurAirports, OA on Observable\nISO 2-character country codes: ISO2C\n(meaningful) Time and dates formats: ISO 8601\nICAO aircraft type designator, WTC and more: ICAO aircraft type designator page\n\n\n\nTrajectory\nThe daily trajectory files contain:\n\nflight identification: unique ID (flight_id, same as for flight list), (obfuscated) ICAO 24-bit address (icao24, same value as flight_id)\n4D position: longitude [DD, decimal degrees in -90/90 range] and latitude [DD, decimal degrees in -180/180 range], altitude [ft], timestamp [timestamp with time zone]\nspeed: ground speed (groundspeed [kt]), track angle (track and track_unwrapped [decimal degrees]), vertical rate of climb/descent (vertical_rate [ft/min])\n(optionally) meteo info at 4D position:\n\nwind (u_component_of_wind and v_component_of_wind) [m/s]\ntemperature [\\(K\\), kelvin]\n\n\nThe daily file &lt;yyyy-mm-dd&gt;.parquet includes all position reports on (UTC) &lt;yyyy-mm-dd&gt; date, it then can happen that flight portions be present in consecutive files, i.e. the same flight_id will occur in more than one daily file because the flight took place across the (UTC) midnight.\nNOTE: trajectories are not necessarily complete/overlapping with respect to what reported in the flight list in actual_offblock_time or arrival_time. This is due to the possibly limited/partial ADS-B coverage in some parts (or some lower altitudes) of the world.\nFurther info material:\n\nTrack in aviation: SkyBrary page\nGround speed: SkyBrary page\n\n\n\nRationale for the data sets\nOur gut feelings say that Actual TakeOff Weight (ATOW) depends in some forms from:\n\norigin/destination: the great circle distance is of course a factor in terms of how much fuel you will have to tank and hence the take-off weight.\nAlso ADEP or ADES are important because of specific local procedures.\nADEP/ADES could also be important because different AOs plan and execute flights differently from/to the same airport.\ntiming: when you execute a flight, i.e. morning/evening/night, weekly patterns, seasonal trends, local time (?), flight duration calculation, could be a factor to consider\naircraft: of course the (ICAO) type will imply different amounts of fuel needed,\nairline: policies varies, for example for same city-pair one airline could select different alternates from another airline depending on their technical support facilities/contracts.\nAlso AOs have different tanking policies.\noperational: flown route length (different from great circle distance) could better refine ATOW estimation; same for taxi-out duration\ntrajectory: The ADS-B trajectory can help to classify the way a flight has been flown (rate of climb/descent, maximum en-route flight level, …) and hence refine the ATOW estimate."
  },
  {
    "objectID": "data.html#data-for-submission",
    "href": "data.html#data-for-submission",
    "title": "Data",
    "section": "Data for submission",
    "text": "Data for submission\nThe data sets for the submission are organized as follows:\ndata/submission\n├── 258079011.parquet\n├── 258081111.parquet\n├── 258097425.parquet\n├── ...\n└── submission.csv\n\nand consist of\n\n(CSV) list of flight IDs and to-be-estimated TOW, submission.csv, i.e.\nflight_id, tow\n258081039,\n258081111,\n..."
  },
  {
    "objectID": "data.html#ranking",
    "href": "data.html#ranking",
    "title": "Data",
    "section": "Ranking",
    "text": "Ranking\nFor ranking you’ll need to upload your &lt;team&gt;_submission_&lt;POSIX timestamp&gt;.csv file with the estimated TOWs.\nThe RANKING PAGE will be automatically updated every 30 minutes.\nEventually manually reload it, please.\nYou can also get a JSON file with the rankings as:\n$ curl -X 'GET' \\\n  'https://datacomp.opensky-network.org/api/rankings' \\\n  -H 'accept: application/json'\n[{\"mse\":9.752328117373766E9,\"rank\":1,\"competitor_id\":\"team1\",\"file_name\":\"team1_submission_1720690930.csv.gz\"},{\"mse\":9.752339084652348E9,\"rank\":2,\"competitor_id\":\"team2\",\"file_name\":\"team2_submission_1720690929.csv.gz\"}]"
  },
  {
    "objectID": "data.html#footnotes",
    "href": "data.html#footnotes",
    "title": "Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nfrom Google’s Analysis-Ready, Cloud Optimized (ARCO) ERA5:\nERA5 is the fifth generation of the European Centre for Medium-Range Weather Forecasts (ECMWF) Atmospheric Reanalysis, providing hourly estimates of a large number of atmospheric, land, and oceanic climate variables.\nThe Google Cloud Public Dataset Program hosts ERA5 data that spans from 1940 to recent days, covering the Earth on a 30 km grid and resolves the atmosphere using 137 levels from the surface up to a height of 80 km.↩︎"
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "PRC Data Challenge",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe would like to praise the following organisations, companies and individuals for their participation and support in the provision of advise, data and infrastructure for the challenge:\n\nAirlines:\n\nAustrian Airlines\nSwiss\nVueling\n\nOpensky Network: Automatic Dependent Surveillance–Broadcast (ADS-B) trajectories, hosting of the challenge infrastructure. (John Fitzgerald, Allan Tart, Martin Strohmeier, Vincent Lender)\nProf Junzi Sun (TU Delft): for wisely pre-processing, enhancing (meteo via fastmeteo), locally storing OSN trajectories and then making them available for the challenge\nDr Xavier Olive (ONERA): for advise and the invaluable traffic library\nEUROCONTROL: for providing the relevant flight list (via Network Manager) and estimating TakeOff Weight (TOW) (Aviation Intelligence Unit)."
  },
  {
    "objectID": "data.html#eligibility-for-prize",
    "href": "data.html#eligibility-for-prize",
    "title": "Data",
    "section": "Eligibility for Prize",
    "text": "Eligibility for Prize\nThe winning solutions will only be eligible for the awards if all source code and additional data sets used to generate the results from the measurement data will be made available to be published under the GNU GPLv3 license on the OpenSky Network’s github account.\nIn addition, sufficient documentation must be provided to understand and reproduce the results."
  },
  {
    "objectID": "data.html#datasets",
    "href": "data.html#datasets",
    "title": "Data",
    "section": "Datasets",
    "text": "Datasets\nThe submission template file, submission.csv, contains the list of flight IDs for which to estimate the TOW; it is . flight_id, tow   258081039,   258081111,   ...\nThe relevant trajectories are part of the ones provided in the Trajectory dataset."
  },
  {
    "objectID": "data.html#submission",
    "href": "data.html#submission",
    "title": "Data",
    "section": "Submission",
    "text": "Submission\nThe submission template file, submission.csv, contains the list of flight IDs for which to estimate the TOW; it is . flight_id, tow   258081039,   258081111,   ...\nThe relevant trajectories are part of the ones provided in the Trajectory dataset."
  },
  {
    "objectID": "data.html#dataset-for-submission",
    "href": "data.html#dataset-for-submission",
    "title": "Data",
    "section": "Dataset for submission",
    "text": "Dataset for submission\nThe submission template file, competition-data/submission_set.csv, contains the list of flight IDs for which to estimate the TOW; it is .\nflight_id, tow\n258081039,\n258081111,\n...\nThe relevant trajectories are part of the ones provided in the Trajectory dataset."
  },
  {
    "objectID": "data.html#where-to-get-the-datasets",
    "href": "data.html#where-to-get-the-datasets",
    "title": "Data",
    "section": "Where to get the Datasets",
    "text": "Where to get the Datasets\nThe dataset files are hosted on OpenSky Network (OSN) infrastructure.\nUpon registration of your team you should have received the relevant * team name/ID, i.e. cucu * ACCESS_KEY and SECRET_KEY.\nBelow you can find the details on how to access the data sets and submit your results for ranking.\n\nPre-requisites\nThe steps below have been executed on a MBR/macOS machine but it should be easy to apply them to other Unix-like environments (we did similarly on MS Windows via Git Bash.)\n\nInstall MinIO Client for your OS/environment:\n$ brew install minio/stable/mc\nSet an alias up for the challenge data location:\n$ mc alias set dc24 \\\n  https://s3.opensky-network.org/ \\\n  ACCESS_KEY SECRET_KEY\n\n\n\nRead/Write data\nFrom the command line you can\n\nListed the competition buckets\n$ mc ls dc24\n[2024-07-05 04:05:29 CEST]     0B competition-data/\n[2024-07-08 06:10:23 CEST]     0B submissions/\n$ mc ls dc24/competition-data/\n[2024-07-10 10:58:23 CEST]  12MiB STANDARD 2022-01-01.parquet\n[2024-07-10 10:58:34 CEST]  19MiB STANDARD 2022-01-02.parquet\n...\n[2024-07-11 12:41:20 CEST] 164MiB STANDARD challenge_set.csv\n[2024-07-11 12:42:43 CEST] 1.1MiB STANDARD submission_set.csv\nlist the content of the (read-only) competition-data/ bucket\n$ mc ls dc24/competition-data/\n[2024-07-10 10:58:23 CEST]  12MiB STANDARD 2022-01-01.parquet\n[2024-07-10 10:58:34 CEST]  19MiB STANDARD 2022-01-02.parquet\n...\n[2024-07-11 12:41:20 CEST] 164MiB STANDARD challenge_set.csv\n[2024-07-11 12:42:43 CEST] 1.1MiB STANDARD submission_set.csv\ncopy Jan 2022 trajectory files from the (read-only) competition-data/ bucket\n$ mc cp --recursive dc24/competition-data/2022-01 my-local-directory/\ncopy all files from the (read-only) competition-data/ bucket\n$ mc cp --recursive dc24/competition-data/  my-local-directory/\nWrite your team’s submission (assuming team name cucu) to the submissions/ bucket\n$ mc cp ./my_submission.csv  dc24/submissions/\"cucu_submission_$(date +%s).csv\"\n\nNOTE: no team can list the content of the submissions/ bucket; and team cucu can only submit files in the format cucu_submission_&lt;posix timestamp&gt;.csv"
  },
  {
    "objectID": "index.html#eligibility-for-participation",
    "href": "index.html#eligibility-for-participation",
    "title": "PRC Data Challenge",
    "section": "Eligibility for Participation",
    "text": "Eligibility for Participation\nAny data science and/or aviation enthusiast team or individual can participate to the challenge.\nPlease send a team creation email with the following info (this will be publicly visible [apart from emails] in a dedicated teams’ page):\n\nan OpenSky Network (OSN) account (create one if you do not have it yet)\nteam name\nlist of members (names, eventual affiliations, [at least one for correspondence] email addresses)\nwho you are\nrationale for participation\n\nto\n\nchallenge AT opensky-network.org\n\nAfter a little while later, you will receive the relevant access/secret keys to obtain the relevant Data using your OSN account.\nNOTE: Anyone affiliated with OpenSky Network or EUROCONTROL is not eligible to participate to the PRC Data Challenge."
  },
  {
    "objectID": "data.html#wherehow-to-get-the-datasets",
    "href": "data.html#wherehow-to-get-the-datasets",
    "title": "Data",
    "section": "Where/How to get the Datasets",
    "text": "Where/How to get the Datasets\nThe dataset files are hosted on OSN infrastructure.\nUpon registration of your team you should have received the relevant\n\nteam name/ID, i.e. cucu\nACCESS_KEY and SECRET_KEY.\n\nBelow you can find the details on how to access the data sets and submit your results for ranking.\nThe S3 buckets as\n\nUsing MinIO Client\n\nPre-requisites\nThe steps below have been executed on a MBR/macOS machine but it should be easy to apply them to other Unix-like environments (we did similarly on MS Windows via Git Bash.)\n\nInstall MinIO Client for your OS/environment:\n$ brew install minio/stable/mc\nSet an alias up for the challenge data location:\n$ mc alias set dc24 \\\n  https://s3.opensky-network.org/ \\\n  ACCESS_KEY SECRET_KEY\n\n\n\nRead/Write data\nFrom the command line you can\n\nlist the competition buckets\n$ mc ls dc24\n[2024-07-05 04:05:29 CEST]     0B competition-data/\n[2024-07-08 06:10:23 CEST]     0B submissions/\n$ mc ls dc24/competition-data/\n[2024-07-10 10:58:23 CEST]  12MiB STANDARD 2022-01-01.parquet\n[2024-07-10 10:58:34 CEST]  19MiB STANDARD 2022-01-02.parquet\n...\n[2024-07-11 12:41:20 CEST] 164MiB STANDARD challenge_set.csv\n[2024-07-11 12:42:43 CEST] 1.1MiB STANDARD submission_set.csv\nlist the content of the (read-only) competition-data/ bucket\n$ mc ls dc24/competition-data/\n[2024-07-10 10:58:23 CEST]  12MiB STANDARD 2022-01-01.parquet\n[2024-07-10 10:58:34 CEST]  19MiB STANDARD 2022-01-02.parquet\n...\n[2024-07-11 12:41:20 CEST] 164MiB STANDARD challenge_set.csv\n[2024-07-11 12:42:43 CEST] 1.1MiB STANDARD submission_set.csv\ncopy Jan 2022 trajectory files from the (read-only) competition-data/ bucket to a local directory\n$ mc cp --recursive dc24/competition-data/2022-01 my-local-directory/\ncopy all files from the (read-only) competition-data/ bucket to a local directory\n$ mc cp --recursive dc24/competition-data/  my-local-directory/\nWrite your team’s submission (assuming team name cucu) to the submissions/ bucket\n$ mc cp ./my_submission.csv  dc24/submissions/\"cucu_submission_$(date +%s).csv\"\n\nNOTE: no team can list the content of the submissions/ bucket; and team cucu can only submit files in the format cucu_submission_&lt;posix timestamp&gt;.csv\n\n\n\nUsing Python\n\nPre-requisites\nYou need to have pyopensky installed as detailed here.\nAlso your configuration files should contain the relevant values for ACCESS_KEY and SECRET_KEY\n[default]\nusername = your_osn_user\npassword = ...\n\naccess_key = ACCESS_KEY\nsecret_key = SECRET_KEY\n\n\nRead/Write Data\nThe following code allows to download the challenge files\nfrom pyopensky.s3 import S3Client\n\ns3 = S3Client()\n\nfor obj in s3.s3client.list_objects(\"competition-data\", recursive=True):\n     print(f\"{obj.bucket_name=}, {obj.object_name=}\")\n     s3.download_object(obj)\n\n\n\nUsing traffic"
  },
  {
    "objectID": "index.html#the-prize",
    "href": "index.html#the-prize",
    "title": "PRC Data Challenge",
    "section": "The Prize",
    "text": "The Prize\nA total prize of \\(5000\\) EUR will be distributed among the finalists’ teams. Each finalist will receive a prize to acknowledge their innovative ideas and contributions towards solving the posed challenge problem."
  },
  {
    "objectID": "rankings.html",
    "href": "rankings.html",
    "title": "Rankings",
    "section": "",
    "text": "TODO\nfor now reading data from Github…when committing there the webpage just works\n\nd3 = require('d3')\nranks = await d3.csv(\n  \"https://raw.githubusercontent.com/euctrl-pru/prc_data_challenge/202306-release/rankings.csv\"\n)\n\nInputs.table(ranks, { sort: \"ranks\"})"
  }
]